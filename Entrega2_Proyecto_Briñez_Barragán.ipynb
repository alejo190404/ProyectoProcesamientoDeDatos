{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Entrega Proyecto Final Procesamiento de Datos a Gran Escala\n",
        "#Pontificia Universidad Javeriana\n",
        "#John Corredor\n",
        "#Juan Felipe Briñez y Alejandro Barragán\n",
        "#11/Noviembre/2023\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TyfNmmbbAx0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivo:** Aplicar técnicas de ML a conjuntos de datos abiertos para comprender problemas y responder preguntas de negocio"
      ],
      "metadata": {
        "id": "C-WkW7S7BYt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count"
      ],
      "metadata": {
        "id": "1Zt8tMTRhRct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_education = spark.read.csv(\"/FileStore/tables/2016___2017_Health_Education_Report_20231106.csv\")\n",
        "df_poverty = spark.read.csv(\"/FileStore/tables/NYCgov_Poverty_Measure_Data__2018__20231106.csv\")\n",
        "df_arrests = spark.read.csv(\"/FileStore/tables/NYPD_Arrest_Data__Year_to_Date__20231106.csv\")\n",
        "df_accidents = spark.read.csv(\"/FileStore/tables/Motor_Vehicle_Collisions___Vehicles_20231106.csv\")"
      ],
      "metadata": {
        "id": "k_VyX0jVhQpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET HEALTH EDUCATION"
      ],
      "metadata": {
        "id": "HoJ9OeEUhX3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education.printSchema()"
      ],
      "metadata": {
        "id": "OAEuqubHhcKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_education.display()"
      ],
      "metadata": {
        "id": "M75eqif-hf3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRANSFORMACIONES Y FILTROS HEALTH EDUCATION"
      ],
      "metadata": {
        "id": "0dSt0eHiheur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Renombrar las columnas con el nombre que corresponden:\n",
        "- Se hace con el fin de renombrar las columnas para que tengan nombres con sentido y no _c0, _c1, ..."
      ],
      "metadata": {
        "id": "03Mvi3bohrCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Debido a que algunos nombres de los campos son muy largos o usan caracteres, se escogera un nombre representativo para cada uno de ellos:\n",
        "- '# of students in grades 9-12' correspondera a: Students_grades_9_12\n",
        "- '# of students in grades 9-12 scheduled for at least one semester of health instruction' correspondera a: Students_grades_9_12_health\n",
        "- '%' correspondera a: Percentage_at_least_one_semester\n",
        "- '# of 16-17 June and August graduates' correspondera a: Graduates_16_17_june_august\n",
        "- '# of 16-17 June and August graduates meeting high school health requirements' correspondera a: Graduates_16_17_june_august_meeting_requirements\n",
        "- '% 1' correspondera a: Percentage_students_meeting_requirements"
      ],
      "metadata": {
        "id": "NSUFF6R9htfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education = df_education.withColumnRenamed('_c0', 'School_DBN')\n",
        "df_education = df_education.withColumnRenamed('_c1', 'Community_School_District')\n",
        "df_education = df_education.withColumnRenamed('_c2', 'City_Council_District')\n",
        "df_education = df_education.withColumnRenamed('_c3', 'School_Name')\n",
        "df_education = df_education.withColumnRenamed('_c4', 'Students_grades_9_12')\n",
        "df_education = df_education.withColumnRenamed('_c5', 'Students_grades_9_12_health')\n",
        "df_education = df_education.withColumnRenamed('_c6', 'Percentage_at_least_one_semester')\n",
        "df_education = df_education.withColumnRenamed('_c7', 'Graduates_16_17_june_august')\n",
        "df_education = df_education.withColumnRenamed('_c8', 'Graduates_16_17_june_august_meeting_requirements')\n",
        "df_education = df_education.withColumnRenamed('_c9', 'Percentage_students_meeting_requirements')"
      ],
      "metadata": {
        "id": "ll1g6Uo_hoyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1.1. Eliminar el registro que contiene los nombres de los campos\n",
        "- Este registro realmente no tiene información valiosa, pues los nombres de los campos solo aportan eso, el nombre de la columna."
      ],
      "metadata": {
        "id": "mTK6dkpPh0bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education = df_education.filter(df_education.School_DBN != \"School DBN\")\n",
        "display(df_education)"
      ],
      "metadata": {
        "id": "38Hdv3fJh5va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Castear las columnas con el tipo de dato que corresponde\n",
        "- Todos los campos de este dataframe son strings y se necesita tener concordancia con el tipo de dato\n",
        "  - Como algunos datos tienen valores que no corresponden es necesario hacer antes una limpieza de los mismos"
      ],
      "metadata": {
        "id": "yEyOmAcrh9km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.1. Filtrar los datos que tienen una s en donde corresponde un valor numerico\n",
        "- El 22% de los datos tienen un valor de 's', por lo que no aportan información valiosa y al no considerarse representativo, se decide eliminar los mismos"
      ],
      "metadata": {
        "id": "9-xrp2qhiBzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education= df_education.filter(df_education.Students_grades_9_12 != 's')\n",
        "df_education= df_education.filter(df_education.Students_grades_9_12_health != 's')\n",
        "df_education= df_education.filter(df_education.Percentage_at_least_one_semester != 's')\n",
        "df_education= df_education.filter(df_education.Graduates_16_17_june_august != 's')\n",
        "df_education= df_education.filter(df_education.Graduates_16_17_june_august_meeting_requirements != 's')\n",
        "df_education= df_education.filter(df_education.Percentage_students_meeting_requirements != 's')\n",
        "display(df_education)"
      ],
      "metadata": {
        "id": "itw2fLd9iEeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,FloatType\n",
        "\n",
        "df_education = df_education.withColumn(\"Community_School_District\", df_education.Community_School_District.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"City_Council_District\", df_education.City_Council_District.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"Students_grades_9_12\", df_education.Students_grades_9_12.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"Students_grades_9_12_health\", df_education.Students_grades_9_12.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"Percentage_at_least_one_semester\", df_education.Students_grades_9_12.cast(FloatType()))\n",
        "df_education = df_education.withColumn(\"Graduates_16_17_june_august\", df_education.Students_grades_9_12.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"Graduates_16_17_june_august_meeting_requirements\", df_education.Students_grades_9_12.cast(IntegerType()))\n",
        "df_education = df_education.withColumn(\"Percentage_students_meeting_requirements\", df_education.Students_grades_9_12.cast(FloatType()))\n",
        "display(df_education)"
      ],
      "metadata": {
        "id": "1HcO6ZPbiF0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_education.printSchema()"
      ],
      "metadata": {
        "id": "4hkmoSM6iLFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. Eliminar valores nulos"
      ],
      "metadata": {
        "id": "FVaFydNniMR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education = df_education.na.drop()\n",
        "df_education.display()"
      ],
      "metadata": {
        "id": "WUKmpAQOiR-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#DATASET POVERTY"
      ],
      "metadata": {
        "id": "RLc0MhYeiTws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty.printSchema()"
      ],
      "metadata": {
        "id": "SmW9jnaGiWMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty.display()"
      ],
      "metadata": {
        "id": "l4muSuQHiY8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRANSFORMACIONES Y FILTROS POVERTY\n"
      ],
      "metadata": {
        "id": "FRtrLD6dibJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1. Renombrar las columnas con el nombre que corresponden:\n",
        "- Se hace con el fin de renombrar las columnas para que tengan nombres con sentido y no _c0, _c1, ..."
      ],
      "metadata": {
        "id": "QaWbDtnjie1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty = df_poverty.withColumnRenamed('_c0', 'SERIALNO')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c1', 'SPORDER')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c2', 'PWGTP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c3', 'WGTP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c4', 'AGEP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c5', 'CIT')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c6', 'REL')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c7', 'SCH')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c8', 'SCHG')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c9', 'SCHL')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c10', 'SEX')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c11', 'ESR')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c12', 'LANX')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c13', 'ENG')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c14', 'MSP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c15', 'MAR')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c16', 'WKW')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c17', 'WKHP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c18', 'DIS')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c19', 'JWTR')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c20', 'NP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c21', 'TEN')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c22', 'HHT')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c23', 'AgeCateg')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c24', 'Boro')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c25', 'CitizenStatus')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c26', 'EducAttain')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c27', 'EST_Childcare')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c28', 'EST_Commuting')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c29', 'EST_EITC')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c30', 'EST_FICAtax')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c31', 'EST_HEAP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c32', 'EST_Housing')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c33', 'EST_IncomeTax')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c34', 'EST_MOOP')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c35', 'EST_Nutrition')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c36', 'EST_PovGap')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c37', 'EST_PovGapIndex')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c38', 'Ethnicity')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c39', 'FamType_PU')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c40', 'FTPTWork')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c41', 'INTP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c42', 'MRGP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c43', 'NYCgov_Income')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c44', 'NYCgov_Pov_Stat')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c45', 'NYCgov_REL')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c46', 'NYCgov_Threshold')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c47', 'Off_Pov_Stat')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c48', 'Off_Threshold')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c49', 'OI_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c50', 'PA_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c51', 'Povunit_ID')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c52', 'Povunit_Rel')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c53', 'PreTaxIncome_PU')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c54', 'RETP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c55', 'RNTP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c56', 'SEMP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c57', 'SSIP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c58', 'SSP_adj')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c59', 'TotalWorkHrs_PU')\n",
        "df_poverty = df_poverty.withColumnRenamed('_c60', 'WAGP_adj')"
      ],
      "metadata": {
        "id": "68-9_3uQiawv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1.1. Eliminar el registro que contiene los nombres de los campos\n",
        "- Este registro realmente no tiene información valiosa, pues los nombres de los campos solo aportan eso, el nombre de la columna."
      ],
      "metadata": {
        "id": "2rml4Fv5im4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty = df_poverty.filter(df_poverty.SERIALNO != \"SERIALNO\")\n",
        "display(df_poverty)"
      ],
      "metadata": {
        "id": "hdeEWiRQiwE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Castear las columnas con el tipo de dato que corresponde\n",
        "- Todos los campos de este dataframe son strings y se necesita tener concordancia con el tipo de dato\n",
        "  - Como algunos datos tienen valores que no corresponden es necesario hacer antes una limpieza de los mismos"
      ],
      "metadata": {
        "id": "gUeOAEugizUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.1. Eliminar los datos que tienen un valor nulo\n",
        "- El 0.97% de los datos tienen un valor nulo, por lo que no aportan información valiosa y al no considerarse representativo, se decide eliminar los mismos"
      ],
      "metadata": {
        "id": "HprfbCYYi2pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty = df_poverty.na.drop()\n",
        "df_poverty.display()"
      ],
      "metadata": {
        "id": "N9wLMKDCizFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty = df_poverty.withColumn(\"SERIALNO\", df_poverty.SERIALNO.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"SPORDER\", df_poverty.SPORDER.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"PWGTP\", df_poverty.PWGTP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"WGTP\", df_poverty.WGTP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"AGEP\", df_poverty.AGEP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"CIT\", df_poverty.CIT.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"REL\", df_poverty.REL.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"SCH\", df_poverty.SCH.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"SCHG\", df_poverty.SCHG.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"SCHL\", df_poverty.SCHL.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"SEX\", df_poverty.SEX.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"ESR\", df_poverty.ESR.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"LANX\", df_poverty.LANX.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"ENG\", df_poverty.ENG.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"MSP\", df_poverty.MSP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"MAR\", df_poverty.MAR.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"WKW\", df_poverty.WKW.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"WKHP\", df_poverty.WKHP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"DIS\", df_poverty.DIS.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"JWTR\", df_poverty.JWTR.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"NP\", df_poverty.NP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"TEN\", df_poverty.TEN.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"HHT\", df_poverty.HHT.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"AgeCateg\", df_poverty.AgeCateg.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"Boro\", df_poverty.Boro.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"CitizenStatus\", df_poverty.CitizenStatus.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"EducAttain\", df_poverty.EducAttain.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_Childcare\", df_poverty.EST_Childcare.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_Commuting\", df_poverty.EST_Commuting.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_EITC\", df_poverty.EST_EITC.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_FICAtax\", df_poverty.EST_FICAtax.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_HEAP\", df_poverty.EST_HEAP.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_Housing\", df_poverty.EST_Housing.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_IncomeTax\", df_poverty.EST_IncomeTax.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_MOOP\", df_poverty.EST_MOOP.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_Nutrition\", df_poverty.EST_Nutrition.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_PovGap\", df_poverty.EST_PovGap.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"EST_PovGapIndex\", df_poverty.EST_PovGapIndex.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"Ethnicity\", df_poverty.Ethnicity.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"FamType_PU\", df_poverty.FamType_PU.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"FTPTWork\", df_poverty.FTPTWork.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"INTP_adj\", df_poverty.INTP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"MRGP_adj\", df_poverty.MRGP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"NYCgov_Income\", df_poverty.NYCgov_Income.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"NYCgov_Pov_Stat\", df_poverty.NYCgov_Pov_Stat.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"NYCgov_REL\", df_poverty.NYCgov_REL.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"NYCgov_Threshold\", df_poverty.NYCgov_Threshold.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"Off_Pov_Stat\", df_poverty.Off_Pov_Stat.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"Off_Threshold\", df_poverty.Off_Threshold.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"OI_adj\", df_poverty.OI_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"PA_adj\", df_poverty.PA_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"Povunit_ID\", df_poverty.Povunit_ID.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"Povunit_Rel\", df_poverty.Povunit_Rel.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"PreTaxIncome_PU\", df_poverty.PreTaxIncome_PU.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"RETP_adj\", df_poverty.RETP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"RNTP_adj\", df_poverty.RNTP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"SEMP_adj\", df_poverty.SEMP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"SSIP_adj\", df_poverty.SSIP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"SSP_adj\", df_poverty.SSP_adj.cast(FloatType()))\n",
        "df_poverty = df_poverty.withColumn(\"TotalWorkHrs_PU\", df_poverty.TotalWorkHrs_PU.cast(IntegerType()))\n",
        "df_poverty = df_poverty.withColumn(\"WAGP_adj\", df_poverty.WAGP_adj.cast(FloatType()))\n",
        "df_poverty.display()"
      ],
      "metadata": {
        "id": "chBUYV9uiycr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_poverty.printSchema()"
      ],
      "metadata": {
        "id": "JA6Ebl99jCXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# DATASET ARRESTS\n"
      ],
      "metadata": {
        "id": "WbgdTPqAjKYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.printSchema()"
      ],
      "metadata": {
        "id": "J1-I5EvVjP03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "G60rJGm-jSLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1. Renombrar las columnas con el nombre que corresponden:\n",
        "- Se hace con el fin de renombrar las columnas para que tengan nombres con sentido y no _c0, _c1, ..."
      ],
      "metadata": {
        "id": "jcbh5xPYjRg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests = df_arrests.withColumnRenamed('_c0', 'ARREST_KEY',)\n",
        "df_arrests = df_arrests.withColumnRenamed('_c1', 'ARREST_DATE')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c2', 'PD_CD')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c3', 'PD_DESC')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c4', 'KY_CD')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c5', 'OFNS_DESC')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c6', 'LAW_CODE')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c7', 'LAW_CAT_CD')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c8', 'ARREST_BORO')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c9', 'ARREST_PRECINCT')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c10', 'JURISDICTION_CODE')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c11', 'AGE_GROUP')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c12', 'PERP_SEX')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c13', 'PERP_RACE')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c14', 'X_COORD_CD')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c15', 'Y_COORD_CD')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c16', 'Latitude')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c17', 'Longitude')\n",
        "df_arrests = df_arrests.withColumnRenamed('_c18', 'New_Georeferenced_Column')"
      ],
      "metadata": {
        "id": "KmMeP0mNjX19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1.1. Eliminar el registro que contiene los nombres de los campos\n",
        "- Este registro realmente no tiene información valiosa, pues los nombres de los campos solo aportan eso, el nombre de la columna."
      ],
      "metadata": {
        "id": "OrN65KZvjalW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests = df_arrests.filter(df_arrests.ARREST_KEY != 'ARREST_KEY')\n",
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "OWj9MKI_jcdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Castear las columnas con el tipo de dato que corresponde\n",
        "- Todos los campos de este dataframe son strings y se necesita tener concordancia con el tipo de dato\n",
        "  - Como algunos datos tienen valores que no corresponden es necesario hacer antes una limpieza de los mismos"
      ],
      "metadata": {
        "id": "zFOQ8DIZjeOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.1. Eliminar los datos que tienen un valor nulo\n",
        "- El 0.075% de los datos tienen un valor nulo, por lo que no aportan información valiosa y al no considerarse representativo, se decide eliminar los mismos"
      ],
      "metadata": {
        "id": "0Yp0ambojhIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests = df_arrests.na.drop()\n",
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "6eBUDVDyjjic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.2. Transformar el formato de fecha del string para poder hacer el casteo a tipo de dato date posteriormente\n",
        "- El formato de fecha esta en MM/dd/yyyy y necesita estar en yyyy-MM--dd\n"
      ],
      "metadata": {
        "id": "3IjqdiQojlfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "df_arrests = df_arrests.withColumn(\"ARREST_DATE\", to_date(df_arrests[\"ARREST_DATE\"], 'MM/dd/yyyy'))\n",
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "5RkzgVrSjjKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DateType, CharType\n",
        "\n",
        "df_arrests = df_arrests.withColumn(\"ARREST_KEY\", df_arrests.ARREST_KEY.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"PD_CD\", df_arrests.PD_CD.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"KY_CD\", df_arrests.KY_CD.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"ARREST_PRECINCT\", df_arrests.ARREST_PRECINCT.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"JURISDICTION_CODE\", df_arrests.JURISDICTION_CODE.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"X_COORD_CD\", df_arrests.X_COORD_CD.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"Y_COORD_CD\", df_arrests.Y_COORD_CD.cast(IntegerType()))\n",
        "df_arrests = df_arrests.withColumn(\"Latitude\", df_arrests.Latitude.cast(FloatType()))\n",
        "df_arrests = df_arrests.withColumn(\"Longitude\", df_arrests.Longitude.cast(FloatType()))\n",
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "0ohaysMzjtbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.printSchema()"
      ],
      "metadata": {
        "id": "W6YNWxwvjue1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#DATASET ACCIDENTS"
      ],
      "metadata": {
        "id": "mAQUjEv4jxpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents.printSchema()"
      ],
      "metadata": {
        "id": "TPr2kB8SjxeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents.display()"
      ],
      "metadata": {
        "id": "dmAJQRGijw7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1. Renombrar las columnas con el nombre que corresponden:\n",
        "- Se hace con el fin de renombrar las columnas para que tengan nombres con sentido y no _c0, _c1, ..."
      ],
      "metadata": {
        "id": "guzkIz4-j4R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents = df_accidents.withColumnRenamed(\"_c0\", \"UNIQUE_ID\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c1\", \"COLLISION_ID\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c2\", \"CRASH_DATE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c3\", \"CRASH_TIME\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c4\", \"VEHICLE_ID\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c5\", \"STATE_REGISTRATION\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c6\", \"VEHICLE_TYPE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c7\", \"VEHICLE_MAKE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c8\", \"VEHICLE_MODEL\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c9\", \"VEHICLE_YEAR\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c10\", \"TRAVEL_DIRECTION\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c11\", \"VEHICLE_OCCUPANTS\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c12\", \"DRIVER_SEX\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c13\", \"DRIVER_LICENSE_STATUS\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c14\", \"DRIVER_LICENSE_JURISDICTION\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c15\", \"PRE_CRASH\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c16\", \"POINT_OF_IMPACT\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c17\", \"VEHICLE_DAMAGE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c18\", \"VEHICLE_DAMAGE_1\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c19\", \"VEHICLE_DAMAGE_2\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c20\", \"VEHICLE_DAMAGE_3\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c21\", \"PUBLIC_PROPERTY_DAMAGE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c22\", \"PUBLIC_PROPERTY_DAMAGE_TYPE\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c23\", \"CONTRIBUTING_FACTOR_1\")\n",
        "df_accidents = df_accidents.withColumnRenamed(\"_c24\", \"CONTRIBUTING_FACTOR_2\")"
      ],
      "metadata": {
        "id": "18N3Fsbhj7NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###1.1. Eliminar el registro que contiene los nombres de los campos\n",
        "- Este registro realmente no tiene información valiosa, pues los nombres de los campos solo aportan eso, el nombre de la columna."
      ],
      "metadata": {
        "id": "VT5IqVFAj6xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents = df_accidents.filter(df_accidents.UNIQUE_ID != \"UNIQUE_ID\")\n",
        "df_accidents.display()"
      ],
      "metadata": {
        "id": "gGMbDwYHj-Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OGACM6gkkAWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Castear las columnas con el tipo de dato que corresponde\n",
        "- Todos los campos de este dataframe son strings y se necesita tener concordancia con el tipo de dato\n",
        "  - Como algunos datos tienen valores que no corresponden es necesario hacer antes una limpieza de los mismos"
      ],
      "metadata": {
        "id": "VWCR6VsxkAxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.1. Eliminar los datos que tienen un valor nulo\n",
        "- El 0.075% de los datos tienen un valor nulo, por lo que no aportan información valiosa y al no considerarse representativo, se decide eliminar los mismos. Cabe aclarar, que solo se eliminarán los registros que tengan valores nulos en las columnas: \"VEHICLE_TYPE\""
      ],
      "metadata": {
        "id": "sLQ4DTJ9kDLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents = df_accidents.na.drop(subset=[\"VEHICLE_TYPE\"])\n",
        "df_accidents.display()"
      ],
      "metadata": {
        "id": "wBIpRHRIkFOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.2. Transformar el formato de fecha del string para poder hacer el casteo a tipo de dato date posteriormente\n",
        "- El formato de fecha esta en MM/dd/yyyy y necesita estar en yyyy-MM--dd\n"
      ],
      "metadata": {
        "id": "OsY-kqbhkIr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp, date_format, date_trunc, hour, split, col\n",
        "from pyspark.sql.functions import to_date\n",
        "from pyspark.sql.types import IntegerType, FloatType, DateType, CharType\n",
        "df_accidents = df_accidents.withColumn(\"CRASH_DATE\", to_date(df_accidents[\"CRASH_DATE\"], 'MM/dd/yyyy'))\n",
        "df_accidents = df_accidents.withColumn(\"Hora\", split(col(\"CRASH_TIME\"), \":\")[0].cast(IntegerType()))\n",
        "\n"
      ],
      "metadata": {
        "id": "ILHKvWX-kFge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import TimestampType\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df_accidents = df_accidents.withColumn(\"UNIQUE_ID\", df_accidents.UNIQUE_ID.cast(IntegerType()))\n",
        "df_accidents = df_accidents.withColumn(\"COLLISION_ID\", df_accidents.COLLISION_ID.cast(IntegerType()))\n",
        "df_accidents = df_accidents.withColumn(\"VEHICLE_ID\", df_accidents.VEHICLE_ID.cast(IntegerType()))\n",
        "df_accidents = df_accidents.withColumn(\"VEHICLE_YEAR\", df_accidents.VEHICLE_YEAR.cast(IntegerType()))\n",
        "df_accidents = df_accidents.withColumn( \"VEHICLE_OCCUPANTS\", df_accidents.VEHICLE_OCCUPANTS.cast(IntegerType()))\n",
        "\n",
        "df_accidents = df_accidents.withColumn(\"VEHICLE_TYPE\", when(df_accidents[\"VEHICLE_TYPE\"] == \"SPORT UTILITY / STATION WAGON\", \"Station Wagon/Sport Utility Vehicle\").otherwise(df_accidents[\"VEHICLE_TYPE\"]))\n",
        "df_accidents = df_accidents.where(df_accidents.VEHICLE_TYPE!=\"UNKNOWN\")\n",
        "df_accidents = df_accidents.na.drop(subset=[\"VEHICLE_YEAR\"])\n",
        "df_accidents = df_accidents.na.drop(subset=[\"DRIVER_LICENSE_STATUS\"])\n",
        "\n",
        "\n",
        "df_accidents.display()"
      ],
      "metadata": {
        "id": "JWAN7b8ikNH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents.printSchema()"
      ],
      "metadata": {
        "id": "E_5hNDo4kM49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_accidents.display()"
      ],
      "metadata": {
        "id": "S6Gyc1g_kM2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Respuesta a preguntas de negocio planteadas\n",
        "\n",
        "En esta sección, se mostrarán las consultas necesarias para dar respuesta a las preguntas establecidas en la entrega anterior"
      ],
      "metadata": {
        "id": "IUDvafa0kTW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "%md\n",
        "\n",
        "###Pregunta 1: ¿Cuáles son las 5 causas más comunes de arrestos en Nueva York?"
      ],
      "metadata": {
        "id": "eIuDgT7rkVkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "3N6xiEDrkYPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 2: ¿Cuáles son los 5 tipos de vehículos que más accidentes viales tienen?"
      ],
      "metadata": {
        "id": "0wDDUqcEkaK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "8M-hCuaRkaiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 3: ¿Cómo se relaciona la criminalidad con características demográficas (edad, sexo, raza) de los perpetuadores?"
      ],
      "metadata": {
        "id": "LZBg-VUTkkD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "Ady-fdZjkh26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 4: ¿Cómo se relacionan las horas de los accidentes con la frecuencia en la que ocurren? Es decir, ¿hay horas en las que es más común que ocurra un accidente vial?"
      ],
      "metadata": {
        "id": "Ai3x-4Abkp0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "KEcsy10fkhqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 5: ¿Cómo se relaciona el año de manufactura del vehículo con la tasa de accidentalidad?"
      ],
      "metadata": {
        "id": "a45QvCFTkqVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "LcQ95omwkhcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 6: ¿Cómo se relacionan las condiciones antes del choque (dirección de viaje y la última acción antes de colisión) con la seguridad vial?"
      ],
      "metadata": {
        "id": "txKue8lqkq5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "t7rzt-OzkhB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "###Pregunta 7: ¿Cómo se relacionan las características (sexo y licencia de conducción) de los conductores con la frecuencia de accidentes?"
      ],
      "metadata": {
        "id": "ER4KogjKk32I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_arrests.display()"
      ],
      "metadata": {
        "id": "AAM9sLT0kgs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Preparación de los datos\n"
      ],
      "metadata": {
        "id": "9aCwHw-tk6AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lit, row_number\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "#Eliminar columnas que no tendrán valor para predecir\n",
        "columns_to_drop = [\"UNIQUE_ID\", \"COLLISION_ID\", \"CRASH_DATE\", \"CRASH_TIME\", \"VEHICLE_ID\", \"STATE_REGISTRATION\", \"VEHICLE_MAKE\", \"VEHICLE_MODEL\", \"DRIVER_LICENSE_JURISDICTION\", \"POINT_OF_IMPACT\", \"VEHICLE_DAMAGE_1\", \"VEHICLE_DAMAGE_2\", \"VEHICLE_DAMAGE_3\", \"PUBLIC_PROPERTY_DAMAGE\", \"PUBLIC_PROPERTY_DAMAGE_TYPE\", \"CONTRIBUTING_FACTOR_1\", \"CONTRIBUTING_FACTOR_2\", \"TRAVEL_DIRECTION\", \"PRE_CRASH\"]\n",
        "\n",
        "df_accidents = df_accidents.select([column for column in df_accidents.columns if column not in columns_to_drop])\n",
        "\n",
        "\n",
        "#Eliminar registros que no tengan sentido\n",
        "\n",
        "df_accidents = df_accidents.filter(df_accidents[\"VEHICLE_OCCUPANTS\"] != 0)\n",
        "df_accidents = df_accidents.dropna(subset=[\"VEHICLE_DAMAGE\"])\n",
        "\n",
        "#Categorizar VEHICLE_DAMAGE arbitrariamente\n",
        "\n",
        "danio_grave = [\"Right Side Doors\", \"Roof\", \"Overturned\", \"Trailer\", \"Left Side Doors\", \"Demolished\", \"Undercarriage\"]\n",
        "danio_no_grave = [\"Right Front Bumper\", \"Left Rear Bumper\", \"Left Rear Quarter Panel\", \"Center Back End\", \"Left Front Quarter Panel\", \"Right Front Quarter Panel\", \"Other\", \"Right Rear Quarter Panel\", \"Left Front Bumper\", \"Center Front End\", \"Right Rear Bumper\", \"No Damage\"]\n",
        "\n",
        "df_accidents = df_accidents.withColumn(\"VEHICLE_DAMAGE\", when(df_accidents[\"VEHICLE_DAMAGE\"].isin(danio_grave), 1)\n",
        "                                        .when(df_accidents[\"VEHICLE_DAMAGE\"]\n",
        "                                        .isin(danio_no_grave), 0).otherwise(None))\n",
        "\n",
        "#Dar valor numérico a VEHICLE_TYPE según el porcentaje de accidentes. Mientras más veces aparezca registrado en un accidente, más peso tendrá para el modelo\n",
        "\n",
        "counts = df_accidents.groupBy(\"VEHICLE_TYPE\").count()\n",
        "df_accidents = df_accidents.join(counts, on=\"VEHICLE_TYPE\", how=\"left\")\n",
        "df_accidents = df_accidents.withColumn(\"VEHICLE_TYPE\", df_accidents[\"count\"].cast(IntegerType()))\n",
        "df_accidents = df_accidents.drop(\"count\")\n",
        "\n",
        "#Dar valor numérico a DRIVER_SEX. Si es mujer es 1, si es hombre es -1. Se pretende que esto categorice y no afecte la predicción del modelo\n",
        "\n",
        "df_accidents = df_accidents.withColumn(\"DRIVER_SEX\", when(df_accidents[\"DRIVER_SEX\"] == \"F\", int(\"1\")).otherwise(int(\"-1\")))\n",
        "\n",
        "#Dar valor numérico a DRIVER_LICENSE_STATUS\n",
        "\n",
        "df_accidents = df_accidents.withColumn(\"DRIVER_LICENSE_STATUS\", when(df_accidents[\"DRIVER_LICENSE_STATUS\"] == \"Licensed\", int(\"1\")).otherwise(int(0)))\n",
        "\n",
        "df_accidents.show()\n"
      ],
      "metadata": {
        "id": "36gu3eA7k9vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Aplicación de modelos ML"
      ],
      "metadata": {
        "id": "8D8-VeXPlA6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pasar datos a un dataframe de pandas\n",
        "import pandas as pd\n",
        "df = df_accidents.toPandas()\n",
        "df.info()"
      ],
      "metadata": {
        "id": "k92I2oUblCYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Observación\n",
        "- Debido a que el dataset contiene 1473066 datos, se van a tomar 3 muestras aleatorias representativas y a partir de alli se hara un análisis general."
      ],
      "metadata": {
        "id": "G4p7pYsZlE_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tomar 3 muestras aleatorias garantizando la reproducibilidad de los datos\n",
        "\n",
        "porcentaje_muestras = 0.33\n",
        "df_muestra1 = df.sample(frac = porcentaje_muestras)\n",
        "df_muestra2 = df.sample(frac = porcentaje_muestras)\n",
        "df_muestra3 = df.sample(frac = porcentaje_muestras)"
      ],
      "metadata": {
        "id": "B5YWjmd-lHfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muestra1.display()"
      ],
      "metadata": {
        "id": "0dxzykMFlJ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muestra2.display()"
      ],
      "metadata": {
        "id": "NXCRAm3OlMGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_muestra3.display()"
      ],
      "metadata": {
        "id": "WHXRk6FIlNFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Separar los datos"
      ],
      "metadata": {
        "id": "h26Tcr7clQbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Separar los datos para la muestra 1\n",
        "X1 = df_muestra1.drop('VEHICLE_DAMAGE', axis = 1)\n",
        "y1 = df_muestra1['VEHICLE_DAMAGE']\n",
        "\n",
        "X1train, X1test, y1train, y1test = train_test_split(X1, y1, test_size = 0.2)\n",
        "\n",
        "#Separar los datos para la muestra 2\n",
        "X2 = df_muestra2.drop('VEHICLE_DAMAGE', axis = 1)\n",
        "y2 = df_muestra2['VEHICLE_DAMAGE']\n",
        "\n",
        "X2train, X2test, y2train, y2test = train_test_split(X2, y2, test_size = 0.2)\n",
        "\n",
        "#Separar los datos para la muestra 3\n",
        "X3 = df_muestra3.drop('VEHICLE_DAMAGE', axis = 1)\n",
        "y3 = df_muestra3['VEHICLE_DAMAGE']\n",
        "\n",
        "X3train, X3test, y3train, y3test = train_test_split(X3, y3, test_size = 0.2)\n"
      ],
      "metadata": {
        "id": "dE1itTVPlSYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Aprendizaje Supervisado Escogido: Random Forest\n"
      ],
      "metadata": {
        "id": "zT_mutAglWwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model01RF = RandomForestClassifier(\n",
        "            n_estimators = 5,\n",
        "            max_depth    = None,\n",
        "            max_features = 1,\n",
        "            oob_score    = False,\n",
        "            n_jobs       = -1,\n",
        "            random_state = 123) #Parámetros por defecto\n",
        "model01RF.fit(X1train, y1train)\n",
        "prediction1RF = model01RF.predict(X1test)\n",
        "print(classification_report(y1test, prediction1RF))\n",
        "print(confusion_matrix(y1test, prediction1RF))"
      ],
      "metadata": {
        "id": "vaMJ4zY_lZHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model02RF = RandomForestClassifier(\n",
        "            n_estimators = 146,\n",
        "            max_depth    = None,\n",
        "            max_features = 1,\n",
        "            oob_score    = False,\n",
        "            n_jobs       = -1,\n",
        "            random_state = 42) #Cambio del número de árboles utilizando la cantidad de arboles optimos arrojados por Out-of-Bag error\n",
        "model02RF.fit(X2train, y2train)\n",
        "prediction2RF = model02RF.predict(X2test)\n",
        "print(classification_report(y2test, prediction2RF))\n",
        "print(confusion_matrix(y2test, prediction2RF))"
      ],
      "metadata": {
        "id": "BkLf2BG6lg1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model03RF = RandomForestClassifier(n_estimators = 250) #Solo tener un n_estimators = 250\n",
        "model03RF.fit(X3train, y3train)\n",
        "prediction3RF = model03RF.predict(X3test)\n",
        "print(classification_report(y3test, prediction3RF))\n",
        "print(confusion_matrix(y3test, prediction3RF))"
      ],
      "metadata": {
        "id": "yk4srlXQlgm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Reporte de clasificación promediando los resultados de los modelos aplicados en las 3 muestras\n"
      ],
      "metadata": {
        "id": "2KKra0L_lm7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class_report1 = classification_report(y1test, prediction1RF, output_dict=True)\n",
        "class_report2 = classification_report(y2test, prediction2RF, output_dict=True)\n",
        "class_report3 = classification_report(y3test, prediction3RF, output_dict=True)\n",
        "\n",
        "\n",
        "metrics_keys = list(class_report1[\"0\"].keys())  # Obtén las claves de métricas de uno de los informes\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_score_list = []\n",
        "\n",
        "for key in metrics_keys:\n",
        "    precision_values = [class_report1[\"0\"][key], class_report2[\"0\"][key], class_report3[\"0\"][key]]\n",
        "    recall_values = [class_report1[\"1\"][key], class_report2[\"1\"][key], class_report3[\"1\"][key]]\n",
        "    f1_score_values = [class_report1[\"weighted avg\"][key], class_report2[\"weighted avg\"][key], class_report3[\"weighted avg\"][key]]\n",
        "\n",
        "    precision_list.append(np.mean(precision_values))\n",
        "    recall_list.append(np.mean(recall_values))\n",
        "    f1_score_list.append(np.mean(f1_score_values))\n",
        "\n",
        "precision_list = np.round(precision_list, decimals=3)\n",
        "recall_list = np.round(recall_list, decimals=3)\n",
        "f1_score_list = np.round(f1_score_list, decimals=3)\n",
        "\n",
        "average_class_report = {\n",
        "    \"0\": dict(zip(metrics_keys, precision_list)),\n",
        "    \"1\": dict(zip(metrics_keys, recall_list)),\n",
        "    \"weighted avg\": dict(zip(metrics_keys, f1_score_list))\n",
        "}\n",
        "\n",
        "print(\"Informe de Clasificación Promediado:\")\n",
        "print(average_class_report)\n"
      ],
      "metadata": {
        "id": "CaSrbTtclsat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Matriz de confusión promediando los resultados de los modelos aplicados en las 3 muestras\n"
      ],
      "metadata": {
        "id": "jaPYC976lvEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_conf1 = confusion_matrix(y1test, prediction1RF).tolist()\n",
        "matriz_conf2 = confusion_matrix(y2test, prediction2RF).tolist()\n",
        "matriz_conf3 = confusion_matrix(y3test, prediction3RF).tolist()\n",
        "\n",
        "matriz1c = np.array(matriz_conf1)\n",
        "matriz2c = np.array(matriz_conf2)\n",
        "matriz3c = np.array(matriz_conf3)\n",
        "\n",
        "matriz_conf_promediada = (matriz1c + matriz2c + matriz3c) / 3\n",
        "\n",
        "matriz_conf_promediada_redondeada = np.round(matriz_conf_promediada, decimals=3)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print(matriz_conf_promediada_redondeada)\n"
      ],
      "metadata": {
        "id": "Pljgvglll0T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Aprendizaje no supervisado escogido: K-means"
      ],
      "metadata": {
        "id": "etAiHW6ul2FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Crear y ajustar el modelo de k-means\n",
        "model01kmeans = KMeans(n_clusters=2, random_state=69)\n",
        "model01kmeans.fit(X1train)\n",
        "\n",
        "# Obtener las etiquetas de cluster y los centroides\n",
        "labels_train1 = model01kmeans.labels_\n",
        "centroids_train1 = model01kmeans.cluster_centers_\n",
        "\n",
        "# Visualizar los resultados en el conjunto de entrenamiento\n",
        "plt.scatter(X1train.iloc[:, 0], X1train.iloc[:, 1], c=labels_train1, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train1[:, 0], centroids_train1[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Entrenamiento)')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix1 = confusion_matrix(y1train, labels_train1)\n",
        "print(conf_matrix1)\n",
        "\n",
        "# Obtener las etiquetas de cluster para el conjunto de prueba\n",
        "labels_test1 = model01kmeans.predict(X1test)\n",
        "\n",
        "# Visualizar los resultados en el conjunto de prueba\n",
        "plt.scatter(X1test.iloc[:, 0], X1test.iloc[:, 1], c=labels_test1, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train1[:, 0], centroids_train1[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Prueba)')\n",
        "plt.show()\n",
        "\n",
        "# Calcular la matriz de confusión en el conjunto de prueba\n",
        "conf_matrix_test1 = confusion_matrix(y1test, labels_test1)\n",
        "print(conf_matrix_test1)\n",
        "\n",
        "#Calcular metricas especificas para el rendimiento de k-means\n",
        "inertia1 = model01kmeans.inertia_\n",
        "\n"
      ],
      "metadata": {
        "id": "r_wQb60gl3Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y ajustar el modelo de k-means\n",
        "model02kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "model02kmeans.fit(X2train)\n",
        "\n",
        "# Obtener las etiquetas de cluster y los centroides\n",
        "labels_train2 = model02kmeans.labels_\n",
        "centroids_train2 = model02kmeans.cluster_centers_\n",
        "\n",
        "# Visualizar los resultados en el conjunto de entrenamiento\n",
        "plt.scatter(X2train.iloc[:, 0], X2train.iloc[:, 1], c=labels_train2, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train2[:, 0], centroids_train2[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Entrenamiento)')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix2 = confusion_matrix(y2train, labels_train2)\n",
        "print(conf_matrix2)\n",
        "\n",
        "# Obtener las etiquetas de cluster para el conjunto de prueba\n",
        "labels_test2 = model02kmeans.predict(X2test)\n",
        "\n",
        "# Visualizar los resultados en el conjunto de prueba\n",
        "plt.scatter(X2test.iloc[:, 0], X2test.iloc[:, 1], c=labels_test2, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train2[:, 0], centroids_train2[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Prueba)')\n",
        "plt.show()\n",
        "\n",
        "# Calcular la matriz de confusión en el conjunto de prueba\n",
        "conf_matrix_test2 = confusion_matrix(y2test, labels_test2)\n",
        "print(conf_matrix_test2)\n",
        "\n",
        "#Calcular metricas especificas para el rendimiento de k-means\n",
        "inertia2 = model02kmeans.inertia_\n",
        "\n"
      ],
      "metadata": {
        "id": "QM58fBhal50N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear y ajustar el modelo de k-means\n",
        "model03kmeans = KMeans(n_clusters=2, random_state=13)\n",
        "model03kmeans.fit(X3train)\n",
        "\n",
        "# Obtener las etiquetas de cluster y los centroides\n",
        "labels_train3 = model03kmeans.labels_\n",
        "centroids_train3 = model03kmeans.cluster_centers_\n",
        "\n",
        "# Visualizar los resultados en el conjunto de entrenamiento\n",
        "plt.scatter(X3train.iloc[:, 0], X3train.iloc[:, 1], c=labels_train3, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train3[:, 0], centroids_train3[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Entrenamiento)')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix3 = confusion_matrix(y3train, labels_train3)\n",
        "print(conf_matrix3)\n",
        "\n",
        "# Obtener las etiquetas de cluster para el conjunto de prueba\n",
        "labels_test3 = model03kmeans.predict(X3test)\n",
        "\n",
        "# Visualizar los resultados en el conjunto de prueba\n",
        "plt.scatter(X3test.iloc[:, 0], X3test.iloc[:, 1], c=labels_test3, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train3[:, 0], centroids_train3[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('K-Means Clustering (Conjunto de Prueba)')\n",
        "plt.show()\n",
        "\n",
        "# Calcular la matriz de confusión en el conjunto de prueba\n",
        "conf_matrix_test3 = confusion_matrix(y3test, labels_test3)\n",
        "print(conf_matrix_test3)\n",
        "\n",
        "#Calcular metricas especificas para el rendimiento de k-means\n",
        "inertia3 = model03kmeans.inertia_"
      ],
      "metadata": {
        "id": "zqxUdImHl-TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Matriz de confusión promediando los resultados de los modelos aplicados en las 3 muestras\n"
      ],
      "metadata": {
        "id": "jaZOSxHSmFXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "matriz_conf_promediada = (conf_matrix1 + conf_matrix2 + conf_matrix3) / 3\n",
        "\n",
        "matriz_conf_promediada_redondeada = np.round(matriz_conf_promediada, decimals=3)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print(matriz_conf_promediada_redondeada)\n",
        "\n",
        "\n",
        "matriz_conf_promediada2 = (conf_matrix_test1 + conf_matrix_test2 + conf_matrix_test3) / 3\n",
        "\n",
        "matriz_conf_promediada_redondeada2 = np.round(matriz_conf_promediada2, decimals=3)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "print(matriz_conf_promediada_redondeada2)\n"
      ],
      "metadata": {
        "id": "r3UtUPfLmGR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Visualizar las 3 gráficas arrojadas en una sola"
      ],
      "metadata": {
        "id": "GIYhJWqkmOrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar los resultados en el conjunto de entrenamiento\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Gráfica para el modelo 01\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X1train.iloc[:, 0], X1train.iloc[:, 1], c=labels_train1, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train1[:, 0], centroids_train1[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 01 (Entrenamiento)')\n",
        "\n",
        "# Gráfica para el modelo 02\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X2train.iloc[:, 0], X2train.iloc[:, 1], c=labels_train2, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train2[:, 0], centroids_train2[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 02 (Entrenamiento)')\n",
        "\n",
        "# Gráfica para el modelo 03\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X3train.iloc[:, 0], X3train.iloc[:, 1], c=labels_train3, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train3[:, 0], centroids_train3[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 03 (Entrenamiento)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NzgWNGjimP-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar los resultados en el conjunto de prueba\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Gráfica para el modelo 01\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(X1test.iloc[:, 0], X1test.iloc[:, 1], c=labels_test1, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train1[:, 0], centroids_train1[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 01 (Prueba)')\n",
        "\n",
        "# Gráfica para el modelo 02\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(X2test.iloc[:, 0], X2test.iloc[:, 1], c=labels_test2, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train2[:, 0], centroids_train2[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 02 (Prueba)')\n",
        "\n",
        "# Gráfica para el modelo 03\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(X3test.iloc[:, 0], X3test.iloc[:, 1], c=labels_test3, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.scatter(centroids_train3[:, 0], centroids_train3[:, 1], c='red', marker='X', s=200)\n",
        "plt.title('Modelo 03 (Prueba)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LWtS-wenmbFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Promedio de Inercia\n"
      ],
      "metadata": {
        "id": "Jnqk8hjtmgE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promedio_i = (inertia1 + inertia2 + inertia3) / 3\n",
        "print(promedio_i)"
      ],
      "metadata": {
        "id": "eEDPFGAVmkMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}